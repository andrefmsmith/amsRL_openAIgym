{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: Box(2,)\n",
      "action space: Box(1,)\n",
      "  - low: [-1.]\n",
      "  - high: [1.]\n",
      "Training on cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/Desktop/Deep_RL/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "print('observation space:', env.observation_space)\n",
    "print('action space:', env.action_space)\n",
    "print('  - low:', env.action_space.low)\n",
    "print('  - high:', env.action_space.high)\n",
    "print('Training on {}.'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, env, h_size=16):\n",
    "        super(Agent, self).__init__()\n",
    "        self.env = env\n",
    "        # state, hidden layer, action sizes\n",
    "        self.s_size = env.observation_space.shape[0]\n",
    "        self.h_size = h_size\n",
    "        self.a_size = env.action_space.shape[0]\n",
    "        # define layers\n",
    "        self.fc1 = nn.Linear(self.s_size, self.h_size)\n",
    "        self.fc2 = nn.Linear(self.h_size, self.a_size)\n",
    "    \n",
    "    def forward(self,x ):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        return x.cpu().data\n",
    "        \n",
    "    def populate(self, best_wb, noise):\n",
    "        w_fc1 = best_wb[0] + noise*(np.random.randn(self.h_size, self.s_size))#noise*(np.random.rand(self.s_size, self.h_size))\n",
    "        w_fc2 = best_wb[1] + noise*(np.random.randn(self.a_size, self.h_size))#noise*(np.random.rand(self.h_size, self.a_size))\n",
    "        \n",
    "        b_fc1 = best_wb[2] + noise*np.random.randn(self.h_size)\n",
    "        b_fc2 = best_wb[3] + noise*np.random.randn(self.a_size)\n",
    "        return np.array((w_fc1, w_fc2, b_fc1, b_fc2))\n",
    "    \n",
    "    def assign_weights(self, new_weights):\n",
    "        self.fc1.weight.data.copy_(torch.from_numpy(new_weights[0].astype(float)))\n",
    "        self.fc2.weight.data.copy_(torch.from_numpy(new_weights[1].astype(float)))\n",
    "        self.fc1.bias.data.copy_(torch.from_numpy(new_weights[2].astype(float)))\n",
    "        self.fc2.bias.data.copy_(torch.from_numpy(new_weights[3].astype(float)))\n",
    "        \n",
    "    def evaluate(self, weights, gamma=1.0, max_t=5000):\n",
    "        self.assign_weights(weights)\n",
    "        episode_return = 0.0\n",
    "        state = self.env.reset()\n",
    "        for t in range(max_t):\n",
    "            state = torch.from_numpy(state).float().to(device)\n",
    "            action = self.forward(state)\n",
    "            state, reward, done, _ = self.env.step(action)\n",
    "            episode_return += reward * math.pow(gamma, t)\n",
    "            if done:\n",
    "                break\n",
    "        return episode_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cem(n_iterations=500, max_t=1000, gamma=1.0, print_every=10, pop_size=10, topk=3, noise=0.5):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    best_weight = agent.populate([0,0,0,0], noise=1)\n",
    "    \n",
    "    for i_iteration in range(1, n_iterations+1):\n",
    "        weights_pop = [agent.populate(best_weight, noise) for i in range(pop_size)]\n",
    "        rewards = np.array([agent.evaluate(weights, gamma, max_t) for weights in weights_pop])\n",
    "        \n",
    "        elite_idxs = rewards.argsort()[-top_k:]\n",
    "        elite_weights = [weights_pop[i] for i in elite_idxs]\n",
    "        best_weight = np.array(elite_weights).mean(axis=0)\n",
    "        \n",
    "        reward = agent.evaluate(best_weight, gamma=1.0)\n",
    "        scores_deque.append(reward)\n",
    "        scores.append(reward)\n",
    "        \n",
    "        if i_iteration % print_every == 0:\n",
    "            print('Episode {}\\tAverage Score: {:.2f}'.format(i_iteration, np.mean(scores_deque)))\n",
    "\n",
    "        if np.mean(scores_deque)>=90.0:\n",
    "            print('\\nEnvironment solved in {:d} iterations!\\tAverage Score: {:.2f}'.format(i_iteration-100, np.mean(scores_deque)))\n",
    "            break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5435,  0.4337],\n",
      "        [ 0.1759, -0.1078],\n",
      "        [-0.6787,  0.5970],\n",
      "        [-0.5624,  0.6658],\n",
      "        [ 0.0637, -0.5016],\n",
      "        [-0.6866,  0.5928],\n",
      "        [ 0.4005,  0.0614],\n",
      "        [ 0.5549,  0.4862],\n",
      "        [-0.5914,  0.0002],\n",
      "        [ 0.0211,  0.5650],\n",
      "        [ 0.4424, -0.0828],\n",
      "        [-0.0907, -0.4006],\n",
      "        [ 0.5319, -0.6775],\n",
      "        [-0.2055,  0.4269],\n",
      "        [ 0.2030, -0.2235],\n",
      "        [ 0.3039,  0.5185]])\n",
      "Parameter containing:\n",
      "tensor([-0.0614,  0.6316,  0.0161, -0.1616, -0.1852, -0.3757,  0.3215,\n",
      "        -0.5533,  0.3579, -0.5142,  0.0057, -0.6440, -0.2505, -0.2055,\n",
      "        -0.4169,  0.4777])\n",
      "Parameter containing:\n",
      "tensor([[-0.1825, -0.0013, -0.2164, -0.2430,  0.2280,  0.1424, -0.1250,\n",
      "          0.0698,  0.1644, -0.2071,  0.0605,  0.1910,  0.1102,  0.0124,\n",
      "          0.1594, -0.2184]])\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [-8.6033])\n",
      "Episode 10\tAverage Score: -0.00\n",
      "Episode 20\tAverage Score: -0.00\n",
      "Episode 30\tAverage Score: -0.00\n",
      "Episode 40\tAverage Score: -0.00\n",
      "Episode 50\tAverage Score: -0.00\n",
      "Episode 60\tAverage Score: -0.00\n",
      "Episode 70\tAverage Score: -0.00\n",
      "Episode 80\tAverage Score: -0.00\n",
      "Episode 90\tAverage Score: -0.00\n",
      "Episode 100\tAverage Score: -0.00\n",
      "Episode 110\tAverage Score: -0.00\n",
      "Episode 120\tAverage Score: -0.00\n",
      "Episode 130\tAverage Score: -0.00\n",
      "Episode 140\tAverage Score: -0.00\n",
      "Episode 150\tAverage Score: -0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-b1671eab2fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-e3cf8bd6a58d>\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(n_episodes, max_t, gamma, print_every, pop_size, top_k, noise)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mepisode_rewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s_size = 2\n",
    "h_size = 16\n",
    "a_size = 1\n",
    "\n",
    "agent=Agent(env).to(device)\n",
    "\n",
    "for w in agent.parameters():\n",
    "    print(w)\n",
    "scores, returns = cross_entropy(noise=0.5, top_k=3, pop_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0614,  0.1692],\n",
      "        [-0.8823,  1.5956],\n",
      "        [-0.0972,  0.0391],\n",
      "        [-0.5868,  0.2889],\n",
      "        [ 0.7220,  0.3663],\n",
      "        [-0.2734,  0.4492],\n",
      "        [ 0.3824,  0.5011],\n",
      "        [-0.9493, -0.3422],\n",
      "        [ 0.4634, -0.0633],\n",
      "        [ 0.8418,  0.1666],\n",
      "        [ 0.4793,  0.5779],\n",
      "        [-0.5331,  0.0238],\n",
      "        [ 0.2947, -1.0668],\n",
      "        [-0.3186,  0.0386],\n",
      "        [-0.0201,  0.1045],\n",
      "        [ 1.4893,  1.0009]])\n",
      "Parameter containing:\n",
      "tensor([-0.7365,  0.1482,  0.1981, -0.0267, -0.0667,  0.8111, -0.6171,\n",
      "        -0.4651, -0.0031, -0.7924,  0.7831, -1.1438, -0.4139,  0.5018,\n",
      "        -0.1284, -0.2525])\n",
      "Parameter containing:\n",
      "tensor([[ 0.1210, -0.6038,  0.7100,  1.0209,  0.8563,  0.7840,  0.1620,\n",
      "          0.0663,  0.4519,  0.3011, -0.0663, -0.3929,  0.5400, -0.0023,\n",
      "          0.0354,  0.0111]])\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [ 2.6186])\n"
     ]
    }
   ],
   "source": [
    "for w in agent.parameters():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
