# amsRL_openAIgym
In this collection of Jupyter notebooks I experiment with and explore several [openAIgym tasks](https://gym.openai.com/envs/#classic_control).

Each notebook is a reasonably in-depth exploration of a particular task, as opposed to the direct demonstration of a solution. I am using the notebooks as a study tool, documenting my own thoughts, interpretations and intuitions and trying out a range of different things to figure out what works and why, in a bid to advance my understanding of Reinforcement Learning. Be warned that although the notebooks are tidy and documented for my own learning and later revisions, some of my interpretations or assertions could well be wrong. They are correct only to the extent of my (currently incipient) knowledge about RL.

This exploration of openAIgym tasks is being guided by my enrollment in the [Udacity Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893). All of the notebooks are my own independent work, but if you wonder sometimes why a particular method was used as opposed to a different one which may well have been more effective, the answer is likely that I wanted to practise a particular concept learned during the Udacity module I was taking at the time.

With that said, I hope you find this a useful study aid too. openAIgym is a fantastic resource and if you haven't yet, I strongly recommend you experiment with a range of their environments.
